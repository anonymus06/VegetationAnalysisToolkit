% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/DataReading.R
\name{read_NDVI}
\alias{read_NDVI}
\title{Read NDVI Data with Index files}
\usage{
read_NDVI(folder_pathway)
}
\arguments{
\item{folder_pathway}{The path to the folder containing NDVI data and its index files.}
}
\value{
A list containing data frames of NDVI data and index files from all read files,
organized by file name or sheet name for Excel files.
}
\description{
Read NDVI Data with Index files
}
\details{
The function first lists all files in the specified directory. It then iterates over each
file, checking its type and structure before reading the data. For Excel files, it reads each sheet
separately, excluding temporary files that may be generated during file editing. For text files, it
assumes a specific format (tab-separated values) but includes a provision for handling files with
varying structures through potential future enhancements. The function also includes checks to avoid
reading directories or temporary files that might be present in the folder.

Special attention is given to the structure of text files, specifically the need for an empty tab
following the 'description' column to correctly read NDVI values. The function will halt with an
error message if it detects that NDVI values cannot be read due to file structure issues, advising
on potential remedies.
}
\note{
The function assumes a relatively consistent structure for the data files, particularly for the
placement of the NDVI column in text files. If your data deviates significantly from the expected
format, manual adjustments or preprocessing may be necessary before using this function.

Future Improvements:
The current implementation assumes a fixed structure for text files, specifically that they are
tab-separated and that the relevant data starts after skipping the first four rows.
There are two main areas identified for enhancement to improve the robustness and flexibility of this
function:
1. Dynamic Separator Handling:
 - Currently, the function expects the separator to be a tab. However, data files may use
   different separators (e.g., spaces, commas).
 - A potential improvement is to automatically detect and adapt to the file's actual separator.
   This could involve testing for common separators and selecting the one that parses the file correctly.
 - Implementing a tryCatch block or similar error handling could allow the function to attempt
   reading the file with different separators and proceed with the one that succeeds, enhancing
   compatibility with various file formats.
2. Adaptive Row Skipping:
 - The function is hardcoded to skip the first four rows of the text files, assuming these rows
   contain metadata or headers not relevant to the actual data.
 - Files may have a variable number of header or junk rows, requiring a more flexible approach.
 - An improvement could involve analyzing the initial rows of the file to determine where the actual
   data begins. This might include looking for the row where valid data (e.g., numeric values for NDVI)
   first appears or identifying common header patterns to skip.
 - Such adaptive row skipping would make the function more resilient to varying file structures and reduce
   the need for manual file preprocessing.
Implementing these improvements would significantly enhance the function's usability across a broader
range of data file structures, reducing manual adjustments and increasing the efficiency of data
ingestion workflows.
}
